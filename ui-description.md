# Detailed Description of the Mobile AI Agent App UI Sketch

## Overall Layout

This is a hand-drawn sketch on white paper showing multiple mobile phone interface designs for an AI agent application. The sketch contains nine different screen designs arranged in a 3x3 grid pattern, with handwritten notes explaining the functionality of various components. This is a conceptual UI for the mobile AI agent app we've been discussing - a WebKit-powered application that uses WebView for rendering web content, with browser-like tabs for navigation.

## Top Row Wireframes

### Top-Left Screen
This wireframe shows a mobile interface with:
- actual UI hidden in a grey dim and overlaying it is a shown-on-swiping-up based popup (mentioned at the end of this file) that occupies three-fourth of the screen. In this popup, the user chats with the ai agent: 
 - A text content on the top with "USER <- user's message to the AI " text (indicating user identification)
 - Two lines below the user's message. (likely indicating the title of the response of the AI agent.)
 - A large rectangular content area in the middle (for the actual response of the AI agent)
 - At the bottom,  there is a text input component, with three circular buttons:
   - A plus (+) button (likely for uploading media or attachments )
   - A settings icon (for the settings related to the chat like the ai model selector, toggle for web search, etc.)
   - A text input component for the user to type any followup. 

### Top-Middle Screen
This wireframe appears to show:
- A simplified workflow interface
- the nodes of the workflow are arranged in a vertical manner for optimizing for mobile interaction and UX.
- A larger oval shape at the bottom (shown-on-swiping-up based popup mentioned at the end of this file)

### Top-Right Screen
This wireframe displays:
- A canvas. on the canvas, there are:  
 - An image
 - a video player showing a video
 - a line chart
 - an infographic
 - a spredsheet
 - an audio player with an audio
these are all stuff generated by the ai agent (it is multimodal and general-purpose ai agent)

## Middle Row Wireframes

### Middle-Left Screen
This wireframe shows:
- a video player activated when the user clicks on the video from the canvas
below it, there are two things. only one is visible at a time. the user can switch to what he wants. these are: 
- A timeline at the bottom showing ro edit videos (just like in a video editor app). 
the 
- various featues to edit the videos  (just like in a video editor)

### Middle-Middle Screen
This wireframe contains:
- A large rectangular box with these slash command options: "/search" (for regular google search) , "/ask" (for asking something to the ai agent) , "/automate" (for giving a task to the ai agent) and "/expert" (for assigning tasks to the expert agents like "sales sammy", 'tutor tom', etc.)
When any of these slash commands are selected, the rectangular box, becomes a text input component, with the 2 buttons. (like mentioned in the top-left wireframe)
- A large empty space around the rectangular box

### Middle-Right Screen
This wireframe displays a vertical menu (opened when the user clicks on the three-lines icon (three-lines icon is mentioned at the bottom of this file.) ) with various functions:
- A close "X" button at the top to close the menu
- Multiple circular icons with labels:
  - "Account" (with a person icon)
  - "Settings" (with a gear icon)
  - "Integrations" (with a plus icon)
  - "Workflows" (with a flow icon)
  - "Agents Experts" (with a group icon)
  - "Support" (with a question mark)
  - "Summarize Page" (with a document icon)
  - "Ask About Page" (with a question mark)

## Bottom Row Wireframes

### Bottom-Left Screen
This wireframe shows:
- A circular icon with a stickman figure (possibly an expert agent)
- Three rectangular content areas stacked vertically (the user's command to the expert)
- a vertical line with dots as checkpoints. at each checkpoint, the ai agent does one thing (like using an mcp tool, generating an image, searching the web, etc.) . besides each checkpoint, there are previews and descriptions of that one task. 

### Bottom-Middle Screen
This wireframe contains:
- A large empty content area with a green glow around the border (indicates that the ai agent is using the phone of the user to automate a task given to it)
- At the bottom: "CHAT GOING ON..." with four dots (indicating ongoing conversation) inside the shown-on-swiping-up based popup (mentioned at the end of this file)

### Bottom-Right Screen
This wireframe displays:
- 6 tabs 
- Six square shapes arranged in two columns (three on each side). these are 6 tabs (one of the tab preview options chosen by the user, in the settings. mentioned at the end of this file.) 
 - each tab has a title of the webpage at the top of the square and a preview of the webpage in the remainig area of the square. 
On the top of the square tabs, there are 2 things:
 - on the top left there is a circle icon with a stickman icon or an account icon. (indicates whether the tab was opened and/or used by the user or the ai agent)
 - on the top right of the tabs opened or used by the ai agent, there is a small circular icon indicating whether the tab is now dormant (the ai agent is no more performing the task the specific tab was used for) or active (the ai agent is performing the task the specific tab was used for) . the circular icon is in green (for active) or yellow (for dormant). 

## Contextual Meaning for Our Mobile AI Agent App

This sketch represents the UI design for the mobile adaptation of the LemonAI agent we've been discussing. The key elements connect directly to our implementation plan:

1. **WebKit WebView Foundation**: The menubar (mentioned at the end of this file)  in each wireframe represent show that the app can preview webpages 

2. **Browser-Like Tab System**: The multiple screen designs show different states of the tab system, which is central to the mobile browser-like interface we're building.

3. **Mobile Workflow Automation**: The "Workflows" option in the top-right menu directly relates to our plan to implement a simplified workflow engine.

4. **MCP Integration**: The "Integrations" option corresponds to where users would connect Gmail and Notion pieces (MCP services) that we're implementing with WASM.

5. **Accessibility Features**: The large buttons, clear labels, and simple navigation patterns align with our goal of making this accessible to non-technical users.

6. **Agent Modes**: The distinction between "DORMANT" and "ACTIVE" states (shown in bottom-right) relates to our plan to clearly segregate the user's tabs from the agent's tabs.

7. **Always present on screen**: 
- A larger oval shape at the bottom (likely the previously described shown-on-swiping-up based popup)
- browser-like menu bar showing the open tabs, and containing a three-lined icon which shows different options.

This sketch represents a thoughtful design that maintains the core functionality of the LemonAI agent while adapting it to a mobile-first interface with browser-like tab navigation - all while keeping accessibility in mind, which aligns perfectly with our implementation approach of using minimal native components with a JavaScript core.